{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b2bb43-f605-4564-9b18-58f80420e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tokenizer import tokenizer,token2str,vocab_size\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from make_model import make_model\n",
    "from train_and_use import Batch,CrossEntropyLoss,SimpleAdamOptimizer,OptimizerWrapper,train_server_start\n",
    "from train_and_use import El_greedy_decode,El_text_continue,MC_continue,El_text_continue_stream\n",
    "from train_and_use import TOGGLE,STOP\n",
    "from train_and_use import record\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afd30a3-f52b-41b5-9e1c-bd1a6839799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数量:0.18(B)\n"
     ]
    }
   ],
   "source": [
    "model = make_model(\n",
    "    #token是从1开始的，0填充，剩下的用来覆盖全部字节\n",
    "    vocab_size = vocab_size+1+255,\n",
    "    embedding_dim = 768,\n",
    "    key_dim = 128,\n",
    "    head_number = 12,\n",
    "    position_information_type = \"mask\",\n",
    "    # position_information_type = \"sinusoidal\",\n",
    "    # position_information_type = \"rotary\",\n",
    "    # position_information_type = \"learned\",\n",
    "    enable_affine = True,\n",
    "    enable_talking_head = True,\n",
    "    use_diff = False,\n",
    "    self_attention_block_size = 0,\n",
    "    feed_forward_dim = 1536,\n",
    "    enable_layer_norm = True,\n",
    "    deep = 12,\n",
    "    dropout_rate = 0.1,\n",
    "    enable_el_cache = True\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('large_model_13033051.weight',weights_only=True))\n",
    "model = model.eval()\n",
    "parameters_n = 0\n",
    "for p in model.parameters():\n",
    "    parameters_n += p.data.cpu().numpy().size\n",
    "print(\"模型参数量:\"+str(parameters_n/1e9)[:4]+\"(B)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8a046d-79bb-4449-a882-20233106cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# A = ''.join([str(np.random.randint(10)) for _ in range(20)])\n",
    "# B = ''.join([str(np.random.randint(10)) for _ in range(20)])\n",
    "# C = ''.join([str(np.random.randint(10)) for _ in range(20)])\n",
    "# zh_strs = [\"   A\"+A+\"   B\"+B+\"   C\"+C+\"   A\"+A+\"   B\"+B+\"   C\"+C+\"   A\"+A+\"   B\"+B+\"   C\"+C+\"   A\",\n",
    "#            \"   A\"+A+\"   B\"+B+\"   C\"+C+\"   A\"+A+\"   B\"+B+\"   C\"+C+\"   A\"+A+\"   B\"+B+\"   C\"+C+\"   B\",\n",
    "#            \"   A\"+A+\"   B\"+B+\"   C\"+C+\"   A\"+A+\"   B\"+B+\"   C\"+C+\"   A\"+A+\"   B\"+B+\"   C\"+C+\"   C\"]\n",
    "# tokens_batch = [tokenizer(zh_str,5.0) for zh_str in zh_strs]\n",
    "# tokens_batch = np.array(tokens_batch,dtype=np.int64)+255\n",
    "# inputs = torch.from_numpy(tokens_batch).to(device).data\n",
    "# with torch.no_grad():\n",
    "#     out = El_text_continue(\n",
    "#         model,inputs,out_length=20,\n",
    "#         repeat_penalty_value=0.0,\n",
    "#         temperature=0.01,\n",
    "#         decay=0.98\n",
    "#     )\n",
    "# split = ''\n",
    "# for o in out:\n",
    "#     print(token2str(o.cpu().numpy()-255,split=split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7aa617-5738-4a23-98be-631cce0372d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# zh_strs = [\"大家好，\"]*20\n",
    "# tokens_batch = [tokenizer(zh_str,5.0) for zh_str in zh_strs]\n",
    "# tokens_batch = np.array(tokens_batch,dtype=np.int64)+255\n",
    "# inputs = torch.from_numpy(tokens_batch).to(device).data\n",
    "# with torch.no_grad():\n",
    "#     out = El_text_continue(\n",
    "#         model,inputs,out_length=15,\n",
    "#         repeat_penalty_value=0.0,\n",
    "#         temperature=1.0,\n",
    "#         decay=0.98\n",
    "#     )\n",
    "# split = ''\n",
    "# for o in out:\n",
    "#     print(token2str(o.cpu().numpy()-255,split=split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0432955f-5ef0-4be1-89f8-f01acc83b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# zh_strs = [\"苏轼，\"]*1\n",
    "# tokens_batch = [tokenizer(zh_str,5.0) for zh_str in zh_strs]\n",
    "# tokens_batch = np.array(tokens_batch,dtype=np.int64)+255\n",
    "# inputs = torch.from_numpy(tokens_batch).to(device).data\n",
    "# with torch.no_grad():\n",
    "#     out = El_text_continue(\n",
    "#         model,inputs,out_length=128,\n",
    "#         repeat_penalty_value=1.0,\n",
    "#         temperature=0.1,\n",
    "#         decay=0.99\n",
    "#     )\n",
    "# split = ''\n",
    "# for o in out:\n",
    "#     print(token2str(o.cpu().numpy()-255,split=split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2123ef46-10f4-4f98-99dc-3fc0faf5bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('large_model_repeat_stable_cold.weight',weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c52562-c62b-414c-858f-da26f9da5d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明月几时有，把酒问青天。不知天上宫阙，今夕是何年？我欲乘风归去，又恐琼楼玉宇，高处不胜寒。起舞弄清影，何似在人间！转朱阁，低绮户，照无眠。不应有恨，何事长向别时圆？人有悲欢离合总无情，月有CPU times: user 1.06 s, sys: 9.26 ms, total: 1.07 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# zh_strs = [' 1']\n",
    "zh_strs = [\"明月几时有，把酒问青天。不知天上宫阙，\"]\n",
    "# zh_strs = [\"花间一壶酒，独酌无相亲。举杯邀明月，\"]\n",
    "# zh_strs = [\"月落乌啼霜满天，江枫渔火对愁眠。姑苏\"]\n",
    "tokens_batch = [tokenizer(zh_str,5.0) for zh_str in zh_strs]\n",
    "tokens_batch = np.array(tokens_batch,dtype=np.int64)+255\n",
    "inputs = torch.from_numpy(tokens_batch).to(device).data\n",
    "last_len = -1\n",
    "print(zh_strs[0],end='')\n",
    "with torch.no_grad():\n",
    "    for o in El_text_continue_stream(\n",
    "        model,inputs,out_length=64,\n",
    "        repeat_penalty_value=1.0,\n",
    "        temperature=0.1,\n",
    "        decay=0.99\n",
    "    ):\n",
    "        split = ''\n",
    "        if o[0,-1] > 255: #确保是完整的字符才可以输出\n",
    "            print(token2str(o[0][last_len:].cpu().numpy()-255,split=split),end=\"\")\n",
    "            last_len = -1\n",
    "        else:\n",
    "            last_len -= 1\n",
    "        if token2str(o[0][-5:].cpu().numpy()-255,split=split) == '<end':\n",
    "            print('>')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb420c63-4ac8-44b8-a522-3602a4991c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #基于树搜索的推理\n",
    "# zh_str = \"我是一个在大规模语料中训练得到的语言模型，现在我要极力控制自己，不要不断的重复说过的内容。请介绍一下喜鹊这种动物。\"\n",
    "# inc = 0\n",
    "# out_start = 0\n",
    "# print(zh_str,end='')\n",
    "# for i in range(32):\n",
    "#     tokens_batch = tokenizer(zh_str,5.0)\n",
    "#     tokens_batch = np.array(tokens_batch,dtype=np.int64)+255\n",
    "#     inputs = torch.from_numpy(tokens_batch).to(device).data\n",
    "#     with torch.no_grad():\n",
    "#         o = MC_continue(\n",
    "#             model,inputs,out_length=16+inc,\n",
    "#             repeat_penalty_value = 1.0,\n",
    "#             temperature = 1.0,\n",
    "#             try_n = 30,\n",
    "#             acc_n = 30,\n",
    "#             deep_n = 25,\n",
    "#             decay = 0.98\n",
    "#         )\n",
    "#     new_str = token2str(o.cpu().numpy()-255)\n",
    "#     if len(zh_str) == len(new_str):\n",
    "#         inc += 1\n",
    "#     else:\n",
    "#         inc = 0\n",
    "#         out_start = len(zh_str)\n",
    "#         zh_str = new_str\n",
    "#         print(zh_str[out_start:],end='')\n",
    "# print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
