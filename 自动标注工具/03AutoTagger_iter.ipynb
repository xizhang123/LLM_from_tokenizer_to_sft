{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb12b52-f3de-4667-b516-32bcb7a239ee",
   "metadata": {},
   "source": [
    "# 对冷启动数据进行自动标注，减少人工标注时的噪音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72971783-b55d-4f17-b71c-6527fda70882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!AHOCORASICK_BYTES=1 pip install git+https://github.com/WojciechMula/pyahocorasick.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b2bb43-f605-4564-9b18-58f80420e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tokenizer import tokenizer,token2str,vocab_size\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from make_model import make_model\n",
    "from train_and_use import Batch,CrossEntropyLoss,SimpleAdamOptimizer,OptimizerWrapper,train_server_start\n",
    "from train_and_use import text_continue\n",
    "from train_and_use import TOGGLE,STOP\n",
    "from train_and_use import record\n",
    "from collections import Counter,defaultdict\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afd30a3-f52b-41b5-9e1c-bd1a6839799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(\n",
    "    #token是从1开始的，0填充，剩下的用来覆盖全部字节\n",
    "    vocab_size = vocab_size+1+255,\n",
    "    embedding_dim = 512,\n",
    "    key_dim = 256,\n",
    "    head_number = 8,\n",
    "    position_information_type = \"mask\",\n",
    "    # position_information_type = \"sinusoidal\",\n",
    "    # position_information_type = \"rotary\",\n",
    "    # position_information_type = \"learned\",\n",
    "    enable_affine = True,\n",
    "    enable_talking_head = True,\n",
    "    use_diff = False,\n",
    "    self_attention_block_size = 0,\n",
    "    feed_forward_dim = 1024,\n",
    "    enable_layer_norm = True,\n",
    "    deep = 6,\n",
    "    dropout_rate = 0.1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325fb2ab-5209-49e8-9e57-af801158114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('autotagger_init.weight',weights_only=True))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21b7b49-de7f-430f-85c4-261d9119abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_high = open('high_iter.txt','w')\n",
    "file_mid = open('mid_iter.txt','w')\n",
    "file_low  = open('low_iter.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c857e82f-a0f8-4c3a-a5ac-1764c33fe044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 / 3 ]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [01:33<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 / 3 ]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 778/778 [03:51<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 / 3 ]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 413/413 [02:02<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "fnames = ['high_init.txt','mid_init.txt','low_init.txt']\n",
    "np.random.shuffle(fnames)\n",
    "cnt = 0\n",
    "for fname in fnames:\n",
    "    cnt += 1\n",
    "    print('\\r[',cnt,'/',len(fnames),']',end=' '*10)\n",
    "    with open(fname,'r',encoding='utf-8') as f:\n",
    "        lines = [line[:-1] for line in f]\n",
    "        n = len(lines)\n",
    "        n -= n%3\n",
    "        lines = random.sample(lines,n)\n",
    "    # with torch.amp.autocast(\"cuda\"):\n",
    "    for i in tqdm(range(0,len(lines),3)):\n",
    "        tokens_batch = [(tokenizer(lines[i],5.0)+[-255]*1000)[:1000] + tokenizer(' 这段文本的质量按照“高、中、低”三档评价为：',5.0)]\n",
    "        tokens_batch += [(tokenizer(lines[i+1],5.0)+[-255]*1000)[:1000] + tokenizer(' 这段文本的质量按照“高、中、低”三档评价为：',5.0)]\n",
    "        tokens_batch += [(tokenizer(lines[i+2],5.0)+[-255]*1000)[:1000] + tokenizer(' 这段文本的质量按照“高、中、低”三档评价为：',5.0)]\n",
    "        tokens_batch = np.array(tokens_batch,dtype=np.int64)+255\n",
    "        inputs = torch.from_numpy(tokens_batch).to(device).data\n",
    "        with torch.no_grad():\n",
    "            o = text_continue(\n",
    "                model,inputs,out_length=1,\n",
    "                repeat_penalty_value = 0.0,\n",
    "                temperature = 1.0\n",
    "            )\n",
    "        for res,line in zip(o,lines[i:i+3]):\n",
    "            res = token2str(res.cpu().numpy()-255)[-1]\n",
    "            if res == '高':\n",
    "                print(line,file=file_high)\n",
    "            if res == '中':\n",
    "                print(line,file=file_mid)\n",
    "            if res == '低':\n",
    "                print(line,file=file_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ec40ff-0273-44ba-a784-297588f495f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_high.close()\n",
    "file_mid.close()\n",
    "file_low.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
