这部分对应分词器词表创建以及广告清洗的步骤。
由于词表迭代需要对所有数据进行多次分词，且初始词表非常巨大，这里的代码包含需要临时的修改与调试。
耗时操作进行了充分的并行处理，但对内存的需求较大。
经过分析，发现计算速度是瓶颈，可以放心使用交换分区，交换分区建议临时增加到200G。
推测使用pybind11重写分词器代码可以有效加速，当前分词速率约2Mtoken/s/进程。
